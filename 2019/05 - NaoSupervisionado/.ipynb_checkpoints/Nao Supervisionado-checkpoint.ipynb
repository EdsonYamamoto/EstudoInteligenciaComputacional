{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517   19.494944   99.741573    2.295112   \n",
       "std      0.811827    1.117146    0.274344    3.339564   14.282484    0.625851   \n",
       "min     11.030000    0.740000    1.360000   10.600000   70.000000    0.980000   \n",
       "25%     12.362500    1.602500    2.210000   17.200000   88.000000    1.742500   \n",
       "50%     13.050000    1.865000    2.360000   19.500000   98.000000    2.355000   \n",
       "75%     13.677500    3.082500    2.557500   21.500000  107.000000    2.800000   \n",
       "max     14.830000    5.800000    3.230000   30.000000  162.000000    3.880000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     2.029270    0.361854    1.590899    5.058090    0.957449    2.611685   \n",
       "std      0.998859    0.124453    0.572359    2.318286    0.228572    0.709990   \n",
       "min      0.340000    0.130000    0.410000    1.280000    0.480000    1.270000   \n",
       "25%      1.205000    0.270000    1.250000    3.220000    0.782500    1.937500   \n",
       "50%      2.135000    0.340000    1.555000    4.690000    0.965000    2.780000   \n",
       "75%      2.875000    0.437500    1.950000    6.200000    1.120000    3.170000   \n",
       "max      5.080000    0.660000    3.580000   13.000000    1.710000    4.000000   \n",
       "\n",
       "                12  \n",
       "count   178.000000  \n",
       "mean    746.893258  \n",
       "std     314.907474  \n",
       "min     278.000000  \n",
       "25%     500.500000  \n",
       "50%     673.500000  \n",
       "75%     985.000000  \n",
       "max    1680.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados originais: 0.7796610169491526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Acurácia nos dados originais:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número original de atributos: 13\n",
      "Número reduzido de atributos: 3\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print('Número original de atributos:', X_train.shape[1])\n",
    "print('Número reduzido de atributos:', X_test_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados originais: 0.7288135593220338\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print('Acurácia nos dados originais:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components:  1 - Acurácia nos dados originais: 0.6949152542372882\n",
      "Components:  2 - Acurácia nos dados originais: 0.711864406779661\n",
      "Components:  3 - Acurácia nos dados originais: 0.7288135593220338\n",
      "Components:  4 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  5 - Acurácia nos dados originais: 0.7627118644067796\n",
      "Components:  6 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  7 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  8 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  9 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  10 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  11 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  12 - Acurácia nos dados originais: 0.7796610169491526\n",
      "Components:  13 - Acurácia nos dados originais: 0.7796610169491526\n"
     ]
    }
   ],
   "source": [
    "# procurando quantidade de atributos ideais\n",
    "for n in range(1,14):\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "\n",
    "    print('Components: ', n, '- Acurácia nos dados originais:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "fvalue_selector = SelectKBest(f_classif, k=4)\n",
    "X_train_kbest = fvalue_selector.fit_transform(X_train, y_train)\n",
    "X_test_kbest = fvalue_selector.transform(X_test)\n",
    "\n",
    "print('Número original de atributos:', X_train.shape[1])\n",
    "print('Número reduzido de atributos:', X_train_kbest.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Acurácia nos dados originais:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train_kbest, y_train)\n",
    "y_pred = model.predict(X_test_kbest)\n",
    "print('Acurácia nos dados (Kbest):', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procurando quantidade de atributos ideais\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Acurácia nos dados originais:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "baseline = accuracy_score(y_test, y_pred)\n",
    "\n",
    "kbest = []\n",
    "acc   = []\n",
    "\n",
    "for n in range(1,14):\n",
    "    \n",
    "    fvalue_selector = SelectKBest(f_classif, k=n)\n",
    "    X_train_kbest = fvalue_selector.fit_transform(X_train, y_train)\n",
    "    X_test_kbest = fvalue_selector.transform(X_test)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    model.fit(X_train_kbest, y_train)\n",
    "    y_pred = model.predict(X_test_kbest)\n",
    "    \n",
    "    kbest.append(n)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    print('Features:', n, '- Acurácia nos dados (Kbest):', acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "grid = sns.JointGrid(kbest, acc, space=0, size=6, ratio=50)\n",
    "grid.plot_joint(plt.bar, color=\"g\")\n",
    "plt.plot([min(kbest), max(kbest)], [baseline, baseline], linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "persistence = {}\n",
    "persistence['scaler'] = scaler\n",
    "persistence['model']  = model\n",
    "\n",
    "dump(persistence, 'persist.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence = load('persist.joblib')\n",
    "\n",
    "scaler = persistence['scaler']\n",
    "model = persistence['model']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_kbest)\n",
    "\n",
    "print('Acurácia:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construção de alguns conjuntos artificiais\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "np.random.seed(844)\n",
    "clust1 = np.random.normal(5, 2, (1000,2))\n",
    "clust2 = np.random.normal(15, 3, (1000,2))\n",
    "clust3 = np.random.multivariate_normal([17,3], [[1,0],[0,1]], 1000)\n",
    "clust4 = np.random.multivariate_normal([2,16], [[1,0],[0,1]], 1000)\n",
    "dataset1 = np.concatenate((clust1, clust2, clust3, clust4))\n",
    "\n",
    "# we take the first array as the second array has the cluster labels\n",
    "dataset2 = datasets.make_circles(n_samples=1000, factor=.5, noise=.05)[0]\n",
    "\n",
    "# plot clustering output on the two datasets\n",
    "def cluster_plots(set1, set2, colours1 = 'gray', colours2 = 'gray', \n",
    "                  title1 = 'Dataset 1',  title2 = 'Dataset 2'):\n",
    "    fig,(ax1,ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(6, 3)\n",
    "    ax1.set_title(title1,fontsize=14)\n",
    "    ax1.set_xlim(min(set1[:,0]), max(set1[:,0]))\n",
    "    ax1.set_ylim(min(set1[:,1]), max(set1[:,1]))\n",
    "    ax1.scatter(set1[:, 0], set1[:, 1],s=8,lw=0,c= colours1)\n",
    "    ax2.set_title(title2,fontsize=14)\n",
    "    ax2.set_xlim(min(set2[:,0]), max(set2[:,0]))\n",
    "    ax2.set_ylim(min(set2[:,1]), max(set2[:,1]))\n",
    "    ax2.scatter(set2[:, 0], set2[:, 1],s=8,lw=0,c=colours2)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "cluster_plots(dataset1, dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupamento por k-medias\n",
    "kmeans_dataset1 = cluster.KMeans(n_clusters=4, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(dataset1)\n",
    "kmeans_dataset2 = cluster.KMeans(n_clusters=2, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(dataset2)\n",
    "print('Dataset1')\n",
    "print(*[\"Cluster \"+str(i)+\": \"+ str(sum(kmeans_dataset1==i)) for i in range(4)], sep='\\n')\n",
    "cluster_plots(dataset1, dataset2, kmeans_dataset1, kmeans_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensível a densidade, o que acontece em diminuir as amostras?\n",
    "\n",
    "kmeans_dataset3 = cluster.KMeans(n_clusters=4, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(np.vstack([dataset1[:2080,:],\n",
    "                                                                                    dataset1[3000:3080,:]]))\n",
    "kmeans_dataset4 = cluster.KMeans(n_clusters=4, max_iter=300, \n",
    "                                 init='k-means++',n_init=10).fit_predict(np.vstack([dataset1[-2080:,],\n",
    "                                                                                    dataset1[:80,]]))\n",
    "cluster_plots(np.vstack([dataset1[:2080,],dataset1[3000:3080,]]), \n",
    "              np.vstack([dataset1[-2080:,],dataset1[:80,]]), \n",
    "              kmeans_dataset3, kmeans_dataset4,title1='', title2='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_dataset1 = cluster.AgglomerativeClustering(n_clusters=4, affinity='euclidean', \n",
    "                                              linkage='ward').fit_predict(dataset1)\n",
    "hc_dataset2 = cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', \n",
    "                                              linkage='average').fit_predict(dataset2)\n",
    "print(\"Dataset 1\")\n",
    "print(*[\"Cluster \"+str(i)+\": \"+ str(sum(hc_dataset1==i)) for i in range(4)], sep='\\n')\n",
    "cluster_plots(dataset1, dataset2, hc_dataset1, hc_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_dataset3 = cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', \n",
    "                                              linkage='complete').fit_predict(dataset2)\n",
    "connect = kneighbors_graph(dataset2, n_neighbors=5, include_self=False)\n",
    "hc_dataset3_connectivity = cluster.AgglomerativeClustering(n_clusters=2, affinity='euclidean', \n",
    "                                              linkage='complete',connectivity=connect).fit_predict(dataset2)\n",
    "cluster_plots(dataset2, dataset2, hc_dataset3, hc_dataset3_connectivity,\n",
    "             title1='Without Connectivity', title2='With Connectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificacao com KMeans\n",
    "\n",
    "from sklearn.datasets import load_digits, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def clust(dataset_load, n_clusters):\n",
    "\n",
    "    ds = dataset_load()\n",
    "    X = ds.data\n",
    "    y = ds.target\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2019)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Sem clustering:', model.score(X_test, y_test))\n",
    "\n",
    "    km = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "    X_train = km.fit_transform(X_train)\n",
    "    X_test  = km.transform(X_test)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Com clustering:', model.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "print('Digits dataset')\n",
    "clust(load_digits, n_clusters = 3)\n",
    "print()\n",
    "print('Iris dataset')\n",
    "clust(load_iris, n_clusters = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios\n",
    "\n",
    "1. Explore a utilização do PCA e do SelectKBest dentro do Pipeline para simplificar a aplicação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

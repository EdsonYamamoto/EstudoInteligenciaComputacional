{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4) (90,)\n",
      "(60, 4) (60,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def custom_cv_2folds(X):\n",
    "    n = X.shape[0]\n",
    "    i = 1\n",
    "    while i <= 2:\n",
    "        idx = np.arange(n * (i - 1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "        i += 1\n",
    "\n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor n:3\n",
      "3 0.98\n",
      "3 1.0\n",
      "3 0.98\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "n = 3 \n",
    "print(\"valor n:\"+str(n))\n",
    "\n",
    "kfold = KFold(n, True, 1)\n",
    "for train, test in kfold.split(X, y):\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X[train], y[train])\n",
    "    print(n,clf.score(X[train], y[train]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\"diabetes_data.csv\")\n",
    "X = df.drop(columns=[\"diabetes\"])\n",
    "y = df[\"diabetes\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor n:3\n",
      "     pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age\n",
      "1              1       85         66       29        0  26.6  0.351   31\n",
      "2              8      183         64        0        0  23.3  0.672   32\n",
      "4              0      137         40       35      168  43.1  2.288   33\n",
      "5              5      116         74        0        0  25.6  0.201   30\n",
      "6              3       78         50       32       88  31.0  0.248   26\n",
      "7             10      115          0        0        0  35.3  0.134   29\n",
      "9              8      125         96        0        0   0.0  0.232   54\n",
      "10             4      110         92        0        0  37.6  0.191   30\n",
      "12            10      139         80        0        0  27.1  1.441   57\n",
      "15             7      100          0        0        0  30.0  0.484   32\n",
      "18             1      103         30       38       83  43.3  0.183   33\n",
      "20             3      126         88       41      235  39.3  0.704   27\n",
      "21             8       99         84        0        0  35.4  0.388   50\n",
      "22             7      196         90        0        0  39.8  0.451   41\n",
      "24            11      143         94       33      146  36.6  0.254   51\n",
      "25            10      125         70       26      115  31.1  0.205   41\n",
      "26             7      147         76        0        0  39.4  0.257   43\n",
      "27             1       97         66       15      140  23.2  0.487   22\n",
      "28            13      145         82       19      110  22.2  0.245   57\n",
      "29             5      117         92        0        0  34.1  0.337   38\n",
      "30             5      109         75       26        0  36.0  0.546   60\n",
      "32             3       88         58       11       54  24.8  0.267   22\n",
      "33             6       92         92        0        0  19.9  0.188   28\n",
      "36            11      138         76        0        0  33.2  0.420   35\n",
      "37             9      102         76       37        0  32.9  0.665   46\n",
      "38             2       90         68       42        0  38.2  0.503   27\n",
      "39             4      111         72       47      207  37.1  1.390   56\n",
      "42             7      106         92       18        0  22.7  0.235   48\n",
      "43             9      171        110       24      240  45.4  0.721   54\n",
      "44             7      159         64        0        0  27.4  0.294   40\n",
      "..           ...      ...        ...      ...      ...   ...    ...  ...\n",
      "723            5      117         86       30      105  39.1  0.251   42\n",
      "724            1      111         94        0        0  32.8  0.265   45\n",
      "725            4      112         78       40        0  39.4  0.236   38\n",
      "727            0      141         84       26        0  32.4  0.433   22\n",
      "728            2      175         88        0        0  22.9  0.326   22\n",
      "729            2       92         52        0        0  30.1  0.141   22\n",
      "732            2      174         88       37      120  44.5  0.646   24\n",
      "734            2      105         75        0        0  23.3  0.560   53\n",
      "735            4       95         60       32        0  35.4  0.284   28\n",
      "736            0      126         86       27      120  27.4  0.515   21\n",
      "737            8       65         72       23        0  32.0  0.600   42\n",
      "738            2       99         60       17      160  36.6  0.453   21\n",
      "739            1      102         74        0        0  39.5  0.293   42\n",
      "740           11      120         80       37      150  42.3  0.785   48\n",
      "741            3      102         44       20       94  30.8  0.400   26\n",
      "743            9      140         94        0        0  32.7  0.734   45\n",
      "744           13      153         88       37      140  40.6  1.174   39\n",
      "745           12      100         84       33      105  30.0  0.488   46\n",
      "746            1      147         94       41        0  49.3  0.358   27\n",
      "748            3      187         70       22      200  36.4  0.408   36\n",
      "749            6      162         62        0        0  24.3  0.178   50\n",
      "751            1      121         78       39       74  39.0  0.261   28\n",
      "752            3      108         62       24        0  26.0  0.223   25\n",
      "758            1      106         76        0        0  37.5  0.197   26\n",
      "759            6      190         92        0        0  35.5  0.278   66\n",
      "762            9       89         62        0        0  22.5  0.142   33\n",
      "763           10      101         76       48      180  32.9  0.171   63\n",
      "764            2      122         70       27        0  36.8  0.340   27\n",
      "766            1      126         60        0        0  30.1  0.349   47\n",
      "767            1       93         70       31        0  30.4  0.315   23\n",
      "\n",
      "[512 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[  1   2   4   5   6   7   9  10  12  15  18  20  21  22  24  25  26  27\\n  28  29  30  32  33  36  37  38  39  42  43  44  46  48  51  52  53  54\\n  55  58  62  63  64  67  70  71  72  73  75  77  78  79  80  83  86  87\\n  89  91  93  94  95  96  97  98  99 100 102 105 106 109 110 112 113 115\\n 116 122 123 124 125 126 127 128 129 130 131 133 136 137 138 140 141 142\\n 143 144 145 146 149 150 151 152 153 155 156 157 158 162 163 164 165 166\\n 167 168 169 170 171 174 176 177 178 179 182 183 184 186 188 190 191 192\\n 193 196 197 198 199 200 203 204 206 208 209 210 211 212 213 215 217 219\\n 220 221 222 225 226 227 228 229 230 231 232 234 235 236 237 239 240 243\\n 244 246 249 250 251 252 253 254 256 258 259 260 261 263 264 266 267 269\\n 270 271 272 275 276 278 279 280 281 282 283 284 287 288 289 290 291 292\\n 293 294 295 296 297 300 302 303 304 306 308 309 312 313 314 315 316 317\\n 319 321 322 324 325 326 327 328 330 332 333 336 337 338 340 342 343 344\\n 345 346 347 348 351 356 357 359 360 361 362 363 364 365 367 368 369 370\\n 374 376 377 379 380 381 383 384 386 387 388 390 391 393 395 397 398 401\\n 405 406 407 409 410 413 414 415 416 417 418 419 420 421 423 424 425 427\\n 429 431 433 434 435 438 439 440 441 443 444 447 450 451 453 454 455 456\\n 457 458 460 461 462 464 465 466 468 469 470 471 473 474 475 476 477 478\\n 479 482 484 485 486 487 488 489 490 492 494 495 497 498 499 500 501 503\\n 504 505 508 511 512 513 514 515 517 520 522 523 525 526 528 529 531 532\\n 534 536 537 542 543 544 545 547 548 551 554 555 557 559 561 562 564 565\\n 566 568 569 571 572 573 574 575 576 578 579 580 582 583 584 585 586 588\\n 589 592 593 594 595 596 597 600 602 603 604 605 606 608 609 610 613 615\\n 616 617 618 619 621 622 623 624 625 626 627 630 632 633 636 639 644 645\\n 647 648 649 651 652 653 654 655 656 657 658 659 660 662 665 666 668 671\\n 672 673 675 676 677 678 681 686 687 688 690 691 692 694 695 696 698 700\\n 702 703 704 706 708 709 710 713 715 716 717 719 720 721 723 724 725 727\\n 728 729 732 734 735 736 737 738 739 740 741 743 744 745 746 748 749 751\\n 752 758 759 762 763 764 766 767] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-42fa1133eccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[  1   2   4   5   6   7   9  10  12  15  18  20  21  22  24  25  26  27\\n  28  29  30  32  33  36  37  38  39  42  43  44  46  48  51  52  53  54\\n  55  58  62  63  64  67  70  71  72  73  75  77  78  79  80  83  86  87\\n  89  91  93  94  95  96  97  98  99 100 102 105 106 109 110 112 113 115\\n 116 122 123 124 125 126 127 128 129 130 131 133 136 137 138 140 141 142\\n 143 144 145 146 149 150 151 152 153 155 156 157 158 162 163 164 165 166\\n 167 168 169 170 171 174 176 177 178 179 182 183 184 186 188 190 191 192\\n 193 196 197 198 199 200 203 204 206 208 209 210 211 212 213 215 217 219\\n 220 221 222 225 226 227 228 229 230 231 232 234 235 236 237 239 240 243\\n 244 246 249 250 251 252 253 254 256 258 259 260 261 263 264 266 267 269\\n 270 271 272 275 276 278 279 280 281 282 283 284 287 288 289 290 291 292\\n 293 294 295 296 297 300 302 303 304 306 308 309 312 313 314 315 316 317\\n 319 321 322 324 325 326 327 328 330 332 333 336 337 338 340 342 343 344\\n 345 346 347 348 351 356 357 359 360 361 362 363 364 365 367 368 369 370\\n 374 376 377 379 380 381 383 384 386 387 388 390 391 393 395 397 398 401\\n 405 406 407 409 410 413 414 415 416 417 418 419 420 421 423 424 425 427\\n 429 431 433 434 435 438 439 440 441 443 444 447 450 451 453 454 455 456\\n 457 458 460 461 462 464 465 466 468 469 470 471 473 474 475 476 477 478\\n 479 482 484 485 486 487 488 489 490 492 494 495 497 498 499 500 501 503\\n 504 505 508 511 512 513 514 515 517 520 522 523 525 526 528 529 531 532\\n 534 536 537 542 543 544 545 547 548 551 554 555 557 559 561 562 564 565\\n 566 568 569 571 572 573 574 575 576 578 579 580 582 583 584 585 586 588\\n 589 592 593 594 595 596 597 600 602 603 604 605 606 608 609 610 613 615\\n 616 617 618 619 621 622 623 624 625 626 627 630 632 633 636 639 644 645\\n 647 648 649 651 652 653 654 655 656 657 658 659 660 662 665 666 668 671\\n 672 673 675 676 677 678 681 686 687 688 690 691 692 694 695 696 698 700\\n 702 703 704 706 708 709 710 713 715 716 717 719 720 721 723 724 725 727\\n 728 729 732 734 735 736 737 738 739 740 741 743 744 745 746 748 749 751\\n 752 758 759 762 763 764 766 767] not in index'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\"diabetes_data.csv\")\n",
    "X = df.drop(columns=[\"diabetes\"])\n",
    "y = df[\"diabetes\"].values\n",
    "\n",
    "#X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "n = 3 \n",
    "print(\"valor n:\"+str(n))\n",
    "\n",
    "\n",
    "kfold = KFold(n, True, 1)\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    print(X.loc[train])\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    \n",
    "    knn.fit(X[train], y[train])\n",
    "\n",
    "    y_pred = knn.predict(X[test])\n",
    "    \n",
    "    verdPos = 0\n",
    "    verdNeg = 0\n",
    "    falsoNeg = 0\n",
    "    falsoPos = 0\n",
    "    \n",
    "    total = len(train)\n",
    "    \n",
    "    for cont in range (len(y_test)):\n",
    "        if y_pred.loc[cont] == 0 & y_test.loc[cont] == 0:\n",
    "            verdNeg = 1+verdNeg\n",
    "        if y_pred.loc[cont] == 1 & y_test.loc[cont] == 1:\n",
    "            verdPos = 1+verdPos\n",
    "        if y_pred.loc[cont] == 1 & y_test.loc[cont] == 0:\n",
    "            falsoPos = falsoPos+1\n",
    "        else:\n",
    "            falsoNeg = falsoNeg+1\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verdPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 101 75 79\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\"diabetes_data.csv\")\n",
    "X = df.drop(columns=[\"diabetes\"])\n",
    "y = df[\"diabetes\"].values\n",
    "\n",
    "#X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#split dataset into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "teste = knn.predict(X_test)\n",
    "\n",
    "verdPos = 0\n",
    "verdNeg = 0\n",
    "falsoNeg = 0\n",
    "falsoPos = 0\n",
    "total = len(X_train)+len(y_train)\n",
    "    \n",
    "for cont in range (len(y_test)):\n",
    "    if teste[cont] == 0 & y_test[cont] == 0:\n",
    "        verdNeg = 1+verdNeg\n",
    "    if teste[cont] == 1 & y_test[cont] == 1:\n",
    "        verdPos = 1+verdPos\n",
    "    if teste[cont] == 1 & y_test[cont] == 0:\n",
    "        falsoPos = falsoPos+1\n",
    "    else:\n",
    "        falsoNeg = falsoNeg+1\n",
    "        \n",
    "print(verdPos, verdNeg, falsoPos , falsoNeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27184466019417475\n",
      "0.10504885993485343\n",
      "0.2616822429906542\n",
      "0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "prec = verdPos / (verdPos + falsoPos)\n",
    "print(prec)\n",
    "\n",
    "accur = (verdPos + verdNeg) / total\n",
    "print(accur)\n",
    "\n",
    "revoc = verdPos / (verdPos + falsoNeg)\n",
    "print(revoc)\n",
    "\n",
    "fMed = 2 * (prec * revoc / (prec + revoc))\n",
    "print(fMed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
